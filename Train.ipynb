{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPVNxaMi+8yNn/b4ZQejD73"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9S50U_Y4SJMi"},"outputs":[],"source":["import gc\n","import os\n","import joblib\n","import random\n","import warnings\n","import itertools\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import lightgbm as lgb\n","import xgboost as xgb\n","from itertools import combinations\n","pd.set_option('display.width', 1000)\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","from sklearn.preprocessing import LabelEncoder\n","import warnings; warnings.filterwarnings('ignore')\n","from sklearn.model_selection import StratifiedKFold, train_test_split"]},{"cell_type":"code","source":["def read_data():\n","    train = pd.read_parquet('/content/drive/MyDrive/Kaggle/AmericanExpress/data/train_fe_v1.parquet')\n","    test = pd.read_parquet('/content/drive/MyDrive/Kaggle/AmericanExpress/data/test_fe_v1.parquet')\n","    return train, test\n","\n","class CFG:\n","    seed = 42\n","    n_folds = 5\n","    target = 'target'\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","seed_everything(CFG.seed)\n","\n","def amex_metric(y_true, y_pred):\n","    labels = np.transpose(np.array([y_true, y_pred]))\n","    labels = labels[labels[:, 1].argsort()[::-1]]\n","    weights = np.where(labels[:,0]==0, 20, 1)\n","    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n","    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n","    gini = [0,0]\n","    for i in [1,0]:\n","        labels = np.transpose(np.array([y_true, y_pred]))\n","        labels = labels[labels[:, i].argsort()[::-1]]\n","        weight = np.where(labels[:,0]==0, 20, 1)\n","        weight_random = np.cumsum(weight / np.sum(weight))\n","        total_pos = np.sum(labels[:, 0] *  weight)\n","        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n","        lorentz = cum_pos_found / total_pos\n","        gini[i] = np.sum((lorentz - weight_random) * weight)\n","    return 0.5 * (gini[1]/gini[0] + top_four)"],"metadata":{"id":"L_xo9MZtSWEx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.第一种特征训练"],"metadata":{"id":"-zTi5p8BTp1o"}},{"cell_type":"code","source":["train, test = read_data()"],"metadata":{"id":"CVOG9A0zSjY6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Label encode categorical features\n","cat_features = [\n","    \"B_30\",\n","    \"B_38\",\n","    \"D_114\",\n","    \"D_116\",\n","    \"D_117\",\n","    \"D_120\",\n","    \"D_126\",\n","    \"D_63\",\n","    \"D_64\",\n","    \"D_66\",\n","    \"D_68\"\n","]\n","cat_features = [f\"{cf}_last\" for cf in cat_features]\n","num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n","num_cols = [col for col in num_cols if 'last' in col]\n","for col in num_cols:\n","    train[col + '_round2'] = train[col].round(2)\n","    test[col + '_round2'] = test[col].round(2)\n","\n","# num_cols = [col for col in train.columns if 'last' in col]\n","# num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n","# for col in num_cols:\n","#     try:\n","#         train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n","#         test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n","#     except:\n","#         pass\n","num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n","for col in tqdm(num_cols):\n","    train[col] = train[col].astype(np.float16)\n","    test[col] = test[col].astype(np.float16)"],"metadata":{"id":"k1HBz_zgShMj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def lgb_amex_metric(y_pred, y_true):\n","    y_true = y_true.get_label()\n","    return 'amex_metric', amex_metric(y_true, y_pred), True\n","\n","def train_and_evaluate_lgb(train,seed,save_dir):\n","    # Get feature list\n","    features = [col for col in train.columns if col not in ['customer_ID', CFG.target , 'S_2']]\n","    params = {\n","        'objective': 'binary',\n","        'device_type' : 'gpu',\n","        'metric': \"binary_logloss\",\n","        'boosting': 'dart',\n","        'seed': CFG.seed,\n","        'num_leaves': 100,\n","        'learning_rate': 0.01,\n","        'feature_fraction': 0.20,\n","        'bagging_freq': 10,\n","        'bagging_fraction': 0.50,\n","        'n_jobs': -1,\n","        'lambda_l2': 2,\n","        'min_data_in_leaf': 40\n","        }\n","    # Create a numpy array to store out of folds predictions\n","    oof_predictions = np.zeros(len(train))\n","    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = seed)\n","    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n","        print(' ')\n","        print('-'*50)\n","        print(f'Training fold {fold} with {len(features)} features...')\n","        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n","        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n","        lgb_train = lgb.Dataset(x_train, y_train)\n","        lgb_valid = lgb.Dataset(x_val, y_val)\n","        model = lgb.train(\n","            params = params,\n","            train_set = lgb_train,\n","            num_boost_round = 10500,\n","            valid_sets = [lgb_train, lgb_valid],\n","            early_stopping_rounds = 100,\n","            verbose_eval = 500,\n","            feval = lgb_amex_metric\n","            )\n","        # Save best model\n","        joblib.dump(model, save_dir + f'/lgbm_fold{fold}_seed{seed}_feature_v1.pkl')\n","        val_pred = model.predict(x_val)\n","        oof_predictions[val_ind] = val_pred\n","        print(amex_metric(train[CFG.target].iloc[val_ind],oof_predictions[val_ind]))\n","        # Predict validation\n","        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n","        import gc\n","        gc.collect()\n","    score = amex_metric(train[CFG.target], oof_predictions)\n","    print(f'Our out of folds CV score is {score}')\n","    # Create a dataframe to store out of folds predictions\n","    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n","    oof_df.to_csv(save_dir + f'/oof_lgbm_baseline_{CFG.n_folds}fold_seed{seed}_feature_v1.csv', index = False)"],"metadata":{"id":"49-C7zeDSmGD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_and_evaluate_lgb(train,42,save_dir)\n","train_and_evaluate_lgb(train,52,save_dir)\n","train_and_evaluate_lgb(train,62,save_dir)"],"metadata":{"id":"c8ccCNCSSmMA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pred_lgboost(test,seed,save_dir,version):\n","  features = [col for col in train.columns if col not in ['customer_ID', CFG.target,'S_2']]\n","  for fold in range(5):\n","    test_predictions = np.zeros(len(test))\n","    model = joblib.load(save_dir + f'/lgbm_fold{fold}_seed{seed}_feature_{version}.pkl')\n","    print('get_model')\n","    start_row = 0\n","    step  = len(test) // 5\n","    end_row =  start_row + step\n","    for k in range(6):\n","      print(k,start_row,end_row)\n","      if end_row <= len(test):\n","        test_pred = model.predict(test.loc[start_row:end_row,features])\n","        test_predictions[start_row:end_row+1] += test_pred \n","      else:\n","        test_pred = model.predict(test.loc[start_row:end_row,features])\n","        test_predictions[start_row:end_row+1] += test_pred\n","      start_row += step\n","      end_row += step\n","    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n","    test_df.to_csv(save_dir + f'/test_lgb_baseline_{CFG.n_folds}fold_seed{seed}_{fold}_featurev_{version}.csv', index = False)\n","    del test_pred,test_predictions\n","    for _ in range(5):\n","      gc.collect()"],"metadata":{"id":"6ZG8eaOaSmOu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_lgboost(test,42,save_dir,'v1')\n","pred_lgboost(test,52,save_dir,'v1')\n","pred_lgboost(test,62,save_dir,'v1')"],"metadata":{"id":"jF7o-fNVSmRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_evaluate_xgboost(train,seed,save_dir,version):\n","    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n","    # Get feature list\n","    \n","    params = {\n","          'n_estimators': 27,\n","          'reg_alpha':1.2825193704597235,\n","          'reg_lambda':2.8254513129979624,\n","          'colsample_bytree':0.4,\n","          'subsample':0.6,\n","          'learning_rate':0.006,\n","          'max_depth':7,\n","          'num_leaves':25,\n","          'min_child_samples': 249,\n","          'cat_smooth': 66,\n","          'eval_metric':'logloss',\n","          'objective':'binary:logistic',\n","          'tree_method':'gpu_hist',\n","          'predictor':'gpu_predictor',\n","          'random_state':seed\n","        }\n","    # Create a numpy array to store test predictions\n","    # test_predictions = np.zeros(len(test))\n","    # # Create a numpy array to store out of folds predictions\n","    oof_predictions = np.zeros(len(train))\n","    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = seed)\n","    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n","        print(' ')\n","        print('-'*50)\n","        print(f'Training fold {fold} with {len(features)} features...')\n","        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n","        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n","        xgb_train = xgb.DMatrix(x_train, y_train)\n","        xgb_valid = xgb.DMatrix(x_val, y_val)\n","        watchlist = [(xgb_train, 'train'), (xgb_valid, 'val')]\n","        model = xgb.train(\n","            params,\n","            xgb_train,\n","            10500,\n","            evals = watchlist,\n","            early_stopping_rounds = 100,\n","            verbose_eval = 300,\n","            # feval = lgb_amex_metric\n","            )\n","        # Save best model\n","        joblib.dump(model, save_dir + f'/xgbm_fold{fold}_seed{seed}_feature_{version}.pkl')\n","        val_pred = model.predict(xgb_valid)\n","        oof_predictions[val_ind] = val_pred\n","        print(amex_metric(train[CFG.target].iloc[val_ind],oof_predictions[val_ind]))\n","        # Predict validation\n","        del x_train, x_val, y_train, y_val, xgb_train, xgb_valid\n","        import gc\n","        gc.collect()\n","    score = amex_metric(train[CFG.target], oof_predictions)\n","    print(f'Our out of folds CV score is {score}')\n","    # Create a dataframe to store out of folds predictions\n","    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n","    oof_df.to_csv(save_dir + f'/oof_xgbm_baseline_{CFG.n_folds}fold_seed{seed}_feature_{version}.csv', index = False)"],"metadata":{"id":"BqrZDjFeSmUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_and_evaluate_xgboost(train,42,save_dir,'v1')\n","train_and_evaluate_xgboost(train,52,save_dir,'v1')\n","train_and_evaluate_xgboost(train,62,save_dir,'v1')"],"metadata":{"id":"aL9kWxS8TPfT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pred_xgboost(test,seed,save_dir,version):\n","  features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n","  for fold in range(5):\n","    test_predictions = np.zeros(len(test))\n","    model = joblib.load(save_dir + f'/xgbm_fold{fold}_seed{seed}_feature_{version}.pkl')\n","    print('get_model')\n","    start_row = 0\n","    step  = len(test) // 5\n","    end_row =  start_row + step\n","    for k in range(6):\n","      print(k,start_row,end_row)\n","      if end_row <= len(test):\n","        xgb_test = xgb.DMatrix(data = test.loc[start_row:end_row,features])\n","        test_pred = model.predict(xgb_test)\n","        test_predictions[start_row:end_row+1] += test_pred \n","      else:\n","        xgb_test = xgb.DMatrix(data = test.loc[start_row:end_row,features])\n","        test_pred = model.predict(xgb_test)\n","        test_predictions[start_row:end_row+1] += test_pred\n","      start_row += step\n","      end_row += step\n","    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n","    test_df.to_csv(save_dir + f'/test_xgb_baseline_{CFG.n_folds}fold_seed{seed}_{fold}_feature_{version}.csv', index = False)\n","    del test_pred,test_predictions,xgb_test\n","    for _ in range(5):\n","      gc.collect()"],"metadata":{"id":"JBA9pEFzTPh4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_xgboost(test,42,save_dir,'v1')\n","pred_xgboost(test,52,save_idr,'v1')\n","pred_xgboost(test,62,save_dir,'v1')"],"metadata":{"id":"xxvSZDpWTPka"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 第二种特征训练"],"metadata":{"id":"yY2CXXOQTw42"}},{"cell_type":"code","source":["train = pd.read_parquet('/content/drive/MyDrive/Kaggle/AmericanExpress/data/train_parquet_cols_v2.parquet')\n","test = pd.read_parquet('/content/drive/MyDrive/Kaggle/AmericanExpress/data/test_parquet_cols_v2.parquet')"],"metadata":{"id":"ZPniDTDpTPnO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_and_evaluate_lgb(train,42,'v2')\n","train_and_evaluate_lgbtrain,52,'v2')\n","train_and_evaluate_lgb(train,62,'v2')"],"metadata":{"id":"D6M8XUfSTPqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_lgboost(test,42,'v2')\n","pred_lgboost(test,52,'v2')\n","pred_lgboost(test,62,'v2')"],"metadata":{"id":"k0ncPtZ9TPsk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_and_evaluate_xgboost(train,42,'v2')\n","train_and_evaluate_xgboost(train,52,'v2')\n","train_and_evaluate_xgboost(train,62,'v2')"],"metadata":{"id":"R-KXdUHuTPvm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_xgboost(test,42,'v2')\n","pred_xgboost(test,52,'v2')\n","pred_xgboost(test,62,'v2')"],"metadata":{"id":"4KkjLMKWTPyh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rbHOgLA2XOjV"},"execution_count":null,"outputs":[]}]}